{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "\n",
    "# MNIST Dataset\n",
    "#train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "#                               train=True,\n",
    "#                               transform=transforms.ToTensor(),\n",
    "#                               download=True)\n",
    "#\n",
    "#test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "#                              train=False,\n",
    "#                              transform=transforms.ToTensor())\n",
    "\n",
    "#Load as panda\n",
    "pd_train_dataset = pd.read_csv('./kaggle_data/train.csv')\n",
    "pd_test_dataset = pd.read_csv('./kaggle_data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_dataset_train(Dataset):\n",
    "    \"\"\" train mnist dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):\n",
    "\n",
    "        #Train data\n",
    "        self.len = pd_train_dataset.shape[0]\n",
    "        \n",
    "        self.pt_x_data = torch.from_numpy(np.array(pd_train_dataset.iloc[:,1:].values).reshape(-1, 1, 28, 28).astype(float)).float()        \n",
    "        self.y_data = np.array(pd_train_dataset.iloc[:, :1].values, dtype='float')\n",
    "        self.pt_y_data = torch.from_numpy(self.y_data).long()\n",
    "        \n",
    "     \n",
    "    def __getitem__(self, index):\n",
    "        return self.pt_x_data[index], self.pt_y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "train_dataset = mnist_dataset_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#print (train_dataset.pt_x_data[0,:])\n",
    "print (train_dataset.pt_x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)  #?????? is this line needed? will test without\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        #print (target.shape)\n",
    "        target = target.squeeze_()  #https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss\n",
    "        #print (target.shape)\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            target = target.squeeze_()  #https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdibattista\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\rdibattista\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/42000 (0%)]\tLoss: 24.729904\n",
      "Train Epoch: 1 [640/42000 (2%)]\tLoss: 2.300856\n",
      "Train Epoch: 1 [1280/42000 (3%)]\tLoss: 2.351997\n",
      "Train Epoch: 1 [1920/42000 (5%)]\tLoss: 2.279578\n",
      "Train Epoch: 1 [2560/42000 (6%)]\tLoss: 2.334364\n",
      "Train Epoch: 1 [3200/42000 (8%)]\tLoss: 2.228648\n",
      "Train Epoch: 1 [3840/42000 (9%)]\tLoss: 1.750069\n",
      "Train Epoch: 1 [4480/42000 (11%)]\tLoss: 1.260625\n",
      "Train Epoch: 1 [5120/42000 (12%)]\tLoss: 0.834008\n",
      "Train Epoch: 1 [5760/42000 (14%)]\tLoss: 0.861665\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.798182\n",
      "Train Epoch: 1 [7040/42000 (17%)]\tLoss: 0.625963\n",
      "Train Epoch: 1 [7680/42000 (18%)]\tLoss: 0.525735\n",
      "Train Epoch: 1 [8320/42000 (20%)]\tLoss: 0.422350\n",
      "Train Epoch: 1 [8960/42000 (21%)]\tLoss: 0.591661\n",
      "Train Epoch: 1 [9600/42000 (23%)]\tLoss: 0.679813\n",
      "Train Epoch: 1 [10240/42000 (24%)]\tLoss: 0.626608\n",
      "Train Epoch: 1 [10880/42000 (26%)]\tLoss: 0.579071\n",
      "Train Epoch: 1 [11520/42000 (27%)]\tLoss: 0.668771\n",
      "Train Epoch: 1 [12160/42000 (29%)]\tLoss: 0.490492\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.615212\n",
      "Train Epoch: 1 [13440/42000 (32%)]\tLoss: 0.527693\n",
      "Train Epoch: 1 [14080/42000 (33%)]\tLoss: 0.530249\n",
      "Train Epoch: 1 [14720/42000 (35%)]\tLoss: 0.604001\n",
      "Train Epoch: 1 [15360/42000 (37%)]\tLoss: 0.546837\n",
      "Train Epoch: 1 [16000/42000 (38%)]\tLoss: 0.321137\n",
      "Train Epoch: 1 [16640/42000 (40%)]\tLoss: 0.480685\n",
      "Train Epoch: 1 [17280/42000 (41%)]\tLoss: 0.751867\n",
      "Train Epoch: 1 [17920/42000 (43%)]\tLoss: 0.293275\n",
      "Train Epoch: 1 [18560/42000 (44%)]\tLoss: 0.627826\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.307818\n",
      "Train Epoch: 1 [19840/42000 (47%)]\tLoss: 0.588303\n",
      "Train Epoch: 1 [20480/42000 (49%)]\tLoss: 0.349028\n",
      "Train Epoch: 1 [21120/42000 (50%)]\tLoss: 0.540445\n",
      "Train Epoch: 1 [21760/42000 (52%)]\tLoss: 0.245768\n",
      "Train Epoch: 1 [22400/42000 (53%)]\tLoss: 0.394905\n",
      "Train Epoch: 1 [23040/42000 (55%)]\tLoss: 0.277163\n",
      "Train Epoch: 1 [23680/42000 (56%)]\tLoss: 0.447925\n",
      "Train Epoch: 1 [24320/42000 (58%)]\tLoss: 0.213282\n",
      "Train Epoch: 1 [24960/42000 (59%)]\tLoss: 0.494430\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.301866\n",
      "Train Epoch: 1 [26240/42000 (62%)]\tLoss: 0.121556\n",
      "Train Epoch: 1 [26880/42000 (64%)]\tLoss: 0.384067\n",
      "Train Epoch: 1 [27520/42000 (65%)]\tLoss: 0.184661\n",
      "Train Epoch: 1 [28160/42000 (67%)]\tLoss: 0.350971\n",
      "Train Epoch: 1 [28800/42000 (68%)]\tLoss: 0.392274\n",
      "Train Epoch: 1 [29440/42000 (70%)]\tLoss: 0.257239\n",
      "Train Epoch: 1 [30080/42000 (72%)]\tLoss: 0.353511\n",
      "Train Epoch: 1 [30720/42000 (73%)]\tLoss: 0.232963\n",
      "Train Epoch: 1 [31360/42000 (75%)]\tLoss: 0.125897\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.226227\n",
      "Train Epoch: 1 [32640/42000 (78%)]\tLoss: 0.086283\n",
      "Train Epoch: 1 [33280/42000 (79%)]\tLoss: 0.154218\n",
      "Train Epoch: 1 [33920/42000 (81%)]\tLoss: 0.292610\n",
      "Train Epoch: 1 [34560/42000 (82%)]\tLoss: 0.389667\n",
      "Train Epoch: 1 [35200/42000 (84%)]\tLoss: 0.131980\n",
      "Train Epoch: 1 [35840/42000 (85%)]\tLoss: 0.155776\n",
      "Train Epoch: 1 [36480/42000 (87%)]\tLoss: 0.198807\n",
      "Train Epoch: 1 [37120/42000 (88%)]\tLoss: 0.195425\n",
      "Train Epoch: 1 [37760/42000 (90%)]\tLoss: 0.207658\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.152552\n",
      "Train Epoch: 1 [39040/42000 (93%)]\tLoss: 0.175571\n",
      "Train Epoch: 1 [39680/42000 (94%)]\tLoss: 0.188014\n",
      "Train Epoch: 1 [40320/42000 (96%)]\tLoss: 0.320242\n",
      "Train Epoch: 1 [40960/42000 (97%)]\tLoss: 0.151846\n",
      "Train Epoch: 1 [41600/42000 (99%)]\tLoss: 0.383530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdibattista\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\rdibattista\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1739, Accuracy: 39728/42000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/42000 (0%)]\tLoss: 0.359808\n",
      "Train Epoch: 2 [640/42000 (2%)]\tLoss: 0.500053\n",
      "Train Epoch: 2 [1280/42000 (3%)]\tLoss: 0.250930\n",
      "Train Epoch: 2 [1920/42000 (5%)]\tLoss: 0.257012\n",
      "Train Epoch: 2 [2560/42000 (6%)]\tLoss: 0.146776\n",
      "Train Epoch: 2 [3200/42000 (8%)]\tLoss: 0.202632\n",
      "Train Epoch: 2 [3840/42000 (9%)]\tLoss: 0.329978\n",
      "Train Epoch: 2 [4480/42000 (11%)]\tLoss: 0.118254\n",
      "Train Epoch: 2 [5120/42000 (12%)]\tLoss: 0.110296\n",
      "Train Epoch: 2 [5760/42000 (14%)]\tLoss: 0.098209\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.237347\n",
      "Train Epoch: 2 [7040/42000 (17%)]\tLoss: 0.158721\n",
      "Train Epoch: 2 [7680/42000 (18%)]\tLoss: 0.122189\n",
      "Train Epoch: 2 [8320/42000 (20%)]\tLoss: 0.271338\n",
      "Train Epoch: 2 [8960/42000 (21%)]\tLoss: 0.132050\n",
      "Train Epoch: 2 [9600/42000 (23%)]\tLoss: 0.184200\n",
      "Train Epoch: 2 [10240/42000 (24%)]\tLoss: 0.305332\n",
      "Train Epoch: 2 [10880/42000 (26%)]\tLoss: 0.153942\n",
      "Train Epoch: 2 [11520/42000 (27%)]\tLoss: 0.058209\n",
      "Train Epoch: 2 [12160/42000 (29%)]\tLoss: 0.232150\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.069952\n",
      "Train Epoch: 2 [13440/42000 (32%)]\tLoss: 0.105157\n",
      "Train Epoch: 2 [14080/42000 (33%)]\tLoss: 0.064339\n",
      "Train Epoch: 2 [14720/42000 (35%)]\tLoss: 0.288542\n",
      "Train Epoch: 2 [15360/42000 (37%)]\tLoss: 0.115119\n",
      "Train Epoch: 2 [16000/42000 (38%)]\tLoss: 0.309547\n",
      "Train Epoch: 2 [16640/42000 (40%)]\tLoss: 0.046933\n",
      "Train Epoch: 2 [17280/42000 (41%)]\tLoss: 0.411755\n",
      "Train Epoch: 2 [17920/42000 (43%)]\tLoss: 0.277038\n",
      "Train Epoch: 2 [18560/42000 (44%)]\tLoss: 0.155143\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.135538\n",
      "Train Epoch: 2 [19840/42000 (47%)]\tLoss: 0.295983\n",
      "Train Epoch: 2 [20480/42000 (49%)]\tLoss: 0.163638\n",
      "Train Epoch: 2 [21120/42000 (50%)]\tLoss: 0.256523\n",
      "Train Epoch: 2 [21760/42000 (52%)]\tLoss: 0.226495\n",
      "Train Epoch: 2 [22400/42000 (53%)]\tLoss: 0.101970\n",
      "Train Epoch: 2 [23040/42000 (55%)]\tLoss: 0.020028\n",
      "Train Epoch: 2 [23680/42000 (56%)]\tLoss: 0.068259\n",
      "Train Epoch: 2 [24320/42000 (58%)]\tLoss: 0.258423\n",
      "Train Epoch: 2 [24960/42000 (59%)]\tLoss: 0.084714\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.185139\n",
      "Train Epoch: 2 [26240/42000 (62%)]\tLoss: 0.162901\n",
      "Train Epoch: 2 [26880/42000 (64%)]\tLoss: 0.028792\n",
      "Train Epoch: 2 [27520/42000 (65%)]\tLoss: 0.304219\n",
      "Train Epoch: 2 [28160/42000 (67%)]\tLoss: 0.118146\n",
      "Train Epoch: 2 [28800/42000 (68%)]\tLoss: 0.142760\n",
      "Train Epoch: 2 [29440/42000 (70%)]\tLoss: 0.118974\n",
      "Train Epoch: 2 [30080/42000 (72%)]\tLoss: 0.132219\n",
      "Train Epoch: 2 [30720/42000 (73%)]\tLoss: 0.435363\n",
      "Train Epoch: 2 [31360/42000 (75%)]\tLoss: 0.026410\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.124309\n",
      "Train Epoch: 2 [32640/42000 (78%)]\tLoss: 0.214937\n",
      "Train Epoch: 2 [33280/42000 (79%)]\tLoss: 0.080201\n",
      "Train Epoch: 2 [33920/42000 (81%)]\tLoss: 0.151433\n",
      "Train Epoch: 2 [34560/42000 (82%)]\tLoss: 0.165380\n",
      "Train Epoch: 2 [35200/42000 (84%)]\tLoss: 0.071349\n",
      "Train Epoch: 2 [35840/42000 (85%)]\tLoss: 0.112109\n",
      "Train Epoch: 2 [36480/42000 (87%)]\tLoss: 0.038416\n",
      "Train Epoch: 2 [37120/42000 (88%)]\tLoss: 0.124755\n",
      "Train Epoch: 2 [37760/42000 (90%)]\tLoss: 0.164996\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.193690\n",
      "Train Epoch: 2 [39040/42000 (93%)]\tLoss: 0.138837\n",
      "Train Epoch: 2 [39680/42000 (94%)]\tLoss: 0.009121\n",
      "Train Epoch: 2 [40320/42000 (96%)]\tLoss: 0.281623\n",
      "Train Epoch: 2 [40960/42000 (97%)]\tLoss: 0.056019\n",
      "Train Epoch: 2 [41600/42000 (99%)]\tLoss: 0.047901\n",
      "\n",
      "Test set: Average loss: 0.1423, Accuracy: 40233/42000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/42000 (0%)]\tLoss: 0.211508\n",
      "Train Epoch: 3 [640/42000 (2%)]\tLoss: 0.172835\n",
      "Train Epoch: 3 [1280/42000 (3%)]\tLoss: 0.126357\n",
      "Train Epoch: 3 [1920/42000 (5%)]\tLoss: 0.139729\n",
      "Train Epoch: 3 [2560/42000 (6%)]\tLoss: 0.099464\n",
      "Train Epoch: 3 [3200/42000 (8%)]\tLoss: 0.195284\n",
      "Train Epoch: 3 [3840/42000 (9%)]\tLoss: 0.279895\n",
      "Train Epoch: 3 [4480/42000 (11%)]\tLoss: 0.212841\n",
      "Train Epoch: 3 [5120/42000 (12%)]\tLoss: 0.166603\n",
      "Train Epoch: 3 [5760/42000 (14%)]\tLoss: 0.166231\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.076151\n",
      "Train Epoch: 3 [7040/42000 (17%)]\tLoss: 0.154174\n",
      "Train Epoch: 3 [7680/42000 (18%)]\tLoss: 0.132624\n",
      "Train Epoch: 3 [8320/42000 (20%)]\tLoss: 0.162059\n",
      "Train Epoch: 3 [8960/42000 (21%)]\tLoss: 0.216620\n",
      "Train Epoch: 3 [9600/42000 (23%)]\tLoss: 0.098365\n",
      "Train Epoch: 3 [10240/42000 (24%)]\tLoss: 0.345605\n",
      "Train Epoch: 3 [10880/42000 (26%)]\tLoss: 0.107638\n",
      "Train Epoch: 3 [11520/42000 (27%)]\tLoss: 0.032808\n",
      "Train Epoch: 3 [12160/42000 (29%)]\tLoss: 0.091514\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.143704\n",
      "Train Epoch: 3 [13440/42000 (32%)]\tLoss: 0.152191\n",
      "Train Epoch: 3 [14080/42000 (33%)]\tLoss: 0.171953\n",
      "Train Epoch: 3 [14720/42000 (35%)]\tLoss: 0.165250\n",
      "Train Epoch: 3 [15360/42000 (37%)]\tLoss: 0.142966\n",
      "Train Epoch: 3 [16000/42000 (38%)]\tLoss: 0.072719\n",
      "Train Epoch: 3 [16640/42000 (40%)]\tLoss: 0.070415\n",
      "Train Epoch: 3 [17280/42000 (41%)]\tLoss: 0.292118\n",
      "Train Epoch: 3 [17920/42000 (43%)]\tLoss: 0.045745\n",
      "Train Epoch: 3 [18560/42000 (44%)]\tLoss: 0.342892\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.068887\n",
      "Train Epoch: 3 [19840/42000 (47%)]\tLoss: 0.056663\n",
      "Train Epoch: 3 [20480/42000 (49%)]\tLoss: 0.077013\n",
      "Train Epoch: 3 [21120/42000 (50%)]\tLoss: 0.074030\n",
      "Train Epoch: 3 [21760/42000 (52%)]\tLoss: 0.281737\n",
      "Train Epoch: 3 [22400/42000 (53%)]\tLoss: 0.115791\n",
      "Train Epoch: 3 [23040/42000 (55%)]\tLoss: 0.045126\n",
      "Train Epoch: 3 [23680/42000 (56%)]\tLoss: 0.094188\n",
      "Train Epoch: 3 [24320/42000 (58%)]\tLoss: 0.097692\n",
      "Train Epoch: 3 [24960/42000 (59%)]\tLoss: 0.227544\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.044183\n",
      "Train Epoch: 3 [26240/42000 (62%)]\tLoss: 0.251293\n",
      "Train Epoch: 3 [26880/42000 (64%)]\tLoss: 0.124125\n",
      "Train Epoch: 3 [27520/42000 (65%)]\tLoss: 0.066832\n",
      "Train Epoch: 3 [28160/42000 (67%)]\tLoss: 0.231915\n",
      "Train Epoch: 3 [28800/42000 (68%)]\tLoss: 0.044975\n",
      "Train Epoch: 3 [29440/42000 (70%)]\tLoss: 0.270371\n",
      "Train Epoch: 3 [30080/42000 (72%)]\tLoss: 0.095620\n",
      "Train Epoch: 3 [30720/42000 (73%)]\tLoss: 0.049879\n",
      "Train Epoch: 3 [31360/42000 (75%)]\tLoss: 0.081686\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.149500\n",
      "Train Epoch: 3 [32640/42000 (78%)]\tLoss: 0.052113\n",
      "Train Epoch: 3 [33280/42000 (79%)]\tLoss: 0.238719\n",
      "Train Epoch: 3 [33920/42000 (81%)]\tLoss: 0.177233\n",
      "Train Epoch: 3 [34560/42000 (82%)]\tLoss: 0.240633\n",
      "Train Epoch: 3 [35200/42000 (84%)]\tLoss: 0.135481\n",
      "Train Epoch: 3 [35840/42000 (85%)]\tLoss: 0.146645\n",
      "Train Epoch: 3 [36480/42000 (87%)]\tLoss: 0.269958\n",
      "Train Epoch: 3 [37120/42000 (88%)]\tLoss: 0.296062\n",
      "Train Epoch: 3 [37760/42000 (90%)]\tLoss: 0.182381\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.270975\n",
      "Train Epoch: 3 [39040/42000 (93%)]\tLoss: 0.271363\n",
      "Train Epoch: 3 [39680/42000 (94%)]\tLoss: 0.153524\n",
      "Train Epoch: 3 [40320/42000 (96%)]\tLoss: 0.058989\n",
      "Train Epoch: 3 [40960/42000 (97%)]\tLoss: 0.213015\n",
      "Train Epoch: 3 [41600/42000 (99%)]\tLoss: 0.145306\n",
      "\n",
      "Test set: Average loss: 0.1256, Accuracy: 40378/42000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/42000 (0%)]\tLoss: 0.161464\n",
      "Train Epoch: 4 [640/42000 (2%)]\tLoss: 0.114474\n",
      "Train Epoch: 4 [1280/42000 (3%)]\tLoss: 0.314171\n",
      "Train Epoch: 4 [1920/42000 (5%)]\tLoss: 0.105257\n",
      "Train Epoch: 4 [2560/42000 (6%)]\tLoss: 0.056587\n",
      "Train Epoch: 4 [3200/42000 (8%)]\tLoss: 0.101967\n",
      "Train Epoch: 4 [3840/42000 (9%)]\tLoss: 0.023863\n",
      "Train Epoch: 4 [4480/42000 (11%)]\tLoss: 0.193360\n",
      "Train Epoch: 4 [5120/42000 (12%)]\tLoss: 0.152281\n",
      "Train Epoch: 4 [5760/42000 (14%)]\tLoss: 0.201170\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.227705\n",
      "Train Epoch: 4 [7040/42000 (17%)]\tLoss: 0.072344\n",
      "Train Epoch: 4 [7680/42000 (18%)]\tLoss: 0.070124\n",
      "Train Epoch: 4 [8320/42000 (20%)]\tLoss: 0.167808\n",
      "Train Epoch: 4 [8960/42000 (21%)]\tLoss: 0.124282\n",
      "Train Epoch: 4 [9600/42000 (23%)]\tLoss: 0.099580\n",
      "Train Epoch: 4 [10240/42000 (24%)]\tLoss: 0.031801\n",
      "Train Epoch: 4 [10880/42000 (26%)]\tLoss: 0.061054\n",
      "Train Epoch: 4 [11520/42000 (27%)]\tLoss: 0.043795\n",
      "Train Epoch: 4 [12160/42000 (29%)]\tLoss: 0.193273\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.059302\n",
      "Train Epoch: 4 [13440/42000 (32%)]\tLoss: 0.017250\n",
      "Train Epoch: 4 [14080/42000 (33%)]\tLoss: 0.159400\n",
      "Train Epoch: 4 [14720/42000 (35%)]\tLoss: 0.038480\n",
      "Train Epoch: 4 [15360/42000 (37%)]\tLoss: 0.133224\n",
      "Train Epoch: 4 [16000/42000 (38%)]\tLoss: 0.031915\n",
      "Train Epoch: 4 [16640/42000 (40%)]\tLoss: 0.013743\n",
      "Train Epoch: 4 [17280/42000 (41%)]\tLoss: 0.201166\n",
      "Train Epoch: 4 [17920/42000 (43%)]\tLoss: 0.163393\n",
      "Train Epoch: 4 [18560/42000 (44%)]\tLoss: 0.207112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.156579\n",
      "Train Epoch: 4 [19840/42000 (47%)]\tLoss: 0.123443\n",
      "Train Epoch: 4 [20480/42000 (49%)]\tLoss: 0.120069\n",
      "Train Epoch: 4 [21120/42000 (50%)]\tLoss: 0.034336\n",
      "Train Epoch: 4 [21760/42000 (52%)]\tLoss: 0.031787\n",
      "Train Epoch: 4 [22400/42000 (53%)]\tLoss: 0.027543\n",
      "Train Epoch: 4 [23040/42000 (55%)]\tLoss: 0.042080\n",
      "Train Epoch: 4 [23680/42000 (56%)]\tLoss: 0.014904\n",
      "Train Epoch: 4 [24320/42000 (58%)]\tLoss: 0.138533\n",
      "Train Epoch: 4 [24960/42000 (59%)]\tLoss: 0.097576\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.125198\n",
      "Train Epoch: 4 [26240/42000 (62%)]\tLoss: 0.062617\n",
      "Train Epoch: 4 [26880/42000 (64%)]\tLoss: 0.127904\n",
      "Train Epoch: 4 [27520/42000 (65%)]\tLoss: 0.325992\n",
      "Train Epoch: 4 [28160/42000 (67%)]\tLoss: 0.035556\n",
      "Train Epoch: 4 [28800/42000 (68%)]\tLoss: 0.070670\n",
      "Train Epoch: 4 [29440/42000 (70%)]\tLoss: 0.148024\n",
      "Train Epoch: 4 [30080/42000 (72%)]\tLoss: 0.306012\n",
      "Train Epoch: 4 [30720/42000 (73%)]\tLoss: 0.090968\n",
      "Train Epoch: 4 [31360/42000 (75%)]\tLoss: 0.110960\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.131325\n",
      "Train Epoch: 4 [32640/42000 (78%)]\tLoss: 0.033260\n",
      "Train Epoch: 4 [33280/42000 (79%)]\tLoss: 0.116233\n",
      "Train Epoch: 4 [33920/42000 (81%)]\tLoss: 0.021672\n",
      "Train Epoch: 4 [34560/42000 (82%)]\tLoss: 0.096875\n",
      "Train Epoch: 4 [35200/42000 (84%)]\tLoss: 0.172992\n",
      "Train Epoch: 4 [35840/42000 (85%)]\tLoss: 0.110471\n",
      "Train Epoch: 4 [36480/42000 (87%)]\tLoss: 0.061227\n",
      "Train Epoch: 4 [37120/42000 (88%)]\tLoss: 0.086769\n",
      "Train Epoch: 4 [37760/42000 (90%)]\tLoss: 0.141490\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.519821\n",
      "Train Epoch: 4 [39040/42000 (93%)]\tLoss: 0.117872\n",
      "Train Epoch: 4 [39680/42000 (94%)]\tLoss: 0.143791\n",
      "Train Epoch: 4 [40320/42000 (96%)]\tLoss: 0.062923\n",
      "Train Epoch: 4 [40960/42000 (97%)]\tLoss: 0.150084\n",
      "Train Epoch: 4 [41600/42000 (99%)]\tLoss: 0.044145\n",
      "\n",
      "Test set: Average loss: 0.0927, Accuracy: 40853/42000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "pt_x_data_test = torch.from_numpy(np.array(pd_test_dataset.iloc[:,:].values).reshape(-1, 1, 28, 28).astype(float)).float()\n",
    "#self.pt_x_data = torch.from_numpy(np.array(pd_train_dataset.iloc[:,1:].values).reshape(-1, 1, 28, 28).astype(float)).float()        \n",
    "#y_data_test = np.array(validation_set.loc[:, ['survived']].values, dtype='float')\n",
    "#pt_y_data_test = torch.from_numpy(self.y_data_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [0],\n",
      "        [9],\n",
      "        ...,\n",
      "        [3],\n",
      "        [9],\n",
      "        [2]])\n"
     ]
    }
   ],
   "source": [
    "#Run test set through\n",
    "model.eval()\n",
    "test_pred = model(pt_x_data_test)\n",
    "#print (test_pred.shape)\n",
    "#print (type(test_pred))\n",
    "#print (test_pred[0,:])\n",
    "\n",
    "pred = test_pred.data.max(1, keepdim=True)[1]\n",
    "print (pred)\n",
    "\n",
    "to_np = pred.detach().numpy()\n",
    "\n",
    "\n",
    "#Add prediction col to test panda\n",
    "#to_np = to_np.astype(int)\n",
    "pd_test_dataset['Label'] = to_np\n",
    "\n",
    "\n",
    "#Export to csv for submission\n",
    "\n",
    "pd_test_dataset.index = np.arange(1, len(pd_test_dataset)+1)\n",
    "pd_test_dataset.to_csv('test.csv', columns = ['Label'], index = True, index_label = 'ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [0],\n",
      "        [9],\n",
      "        ...,\n",
      "        [3],\n",
      "        [9],\n",
      "        [2]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
