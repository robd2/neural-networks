{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1061, -0.2648, -1.2205], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "y = 1\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1061, -0.2648, -1.2205], grad_fn=<MulBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = x * y\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0113, 0.0701, 1.4897], grad_fn=<ThMulBackward>)\n"
     ]
    }
   ],
   "source": [
    "zz = z * z\n",
    "print (zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3115, -1.5271,  0.6817],\n",
      "        [-0.4059,  1.3599, -0.5162],\n",
      "        [ 0.5175,  0.5136, -1.4213]], requires_grad=True)\n",
      "tensor([[ 0.6229, -3.0541,  1.3633],\n",
      "        [-0.8118,  2.7198, -1.0324],\n",
      "        [ 1.0350,  1.0272, -2.8426]], grad_fn=<MulBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8d4521cfc512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "#gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 30, bias=False)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3979, -0.9632,  0.3687,  ...,  0.3078, -0.0313, -0.3832],\n",
      "        [ 0.8841, -0.0237,  0.0224,  ..., -0.4116, -0.7265,  0.6323],\n",
      "        [-1.9711, -1.8030, -0.0817,  ..., -0.2703, -0.6364,  0.3381],\n",
      "        ...,\n",
      "        [ 0.1975, -0.8369, -0.4752,  ...,  0.3476,  0.0847,  0.1286],\n",
      "        [ 0.1463, -0.2244, -0.0451,  ..., -0.1671,  0.7212,  0.1674],\n",
      "        [ 0.8224,  0.8837,  0.1492,  ...,  0.0264, -0.5300,  0.0574]],\n",
      "       grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Parameter containing:\n",
      "tensor([[-0.1055, -0.1876,  0.0046, -0.0772, -0.1089,  0.0276, -0.1450,  0.1895,\n",
      "          0.1889, -0.0686,  0.1130,  0.0535,  0.1389, -0.0405,  0.2050, -0.2172,\n",
      "          0.2120,  0.0993, -0.1854,  0.1946],\n",
      "        [-0.1474,  0.0385, -0.0248,  0.2020, -0.2174, -0.1968, -0.1064,  0.0959,\n",
      "          0.1565,  0.2187,  0.1670,  0.0309, -0.1159, -0.0948,  0.1068,  0.0721,\n",
      "          0.1335, -0.1962,  0.0051,  0.1254],\n",
      "        [ 0.0375,  0.1391, -0.0063,  0.1116,  0.0384,  0.0591,  0.1223, -0.0043,\n",
      "          0.1056,  0.1578,  0.0007, -0.0063, -0.0203, -0.0166,  0.0208, -0.0298,\n",
      "          0.0109, -0.1951,  0.1670,  0.1585],\n",
      "        [-0.0477,  0.0804, -0.0996,  0.0258,  0.0740,  0.0806, -0.0018,  0.1688,\n",
      "          0.1730,  0.1487, -0.0711, -0.0676, -0.0653, -0.0356,  0.0416,  0.1307,\n",
      "         -0.0517, -0.1478, -0.2169,  0.0047],\n",
      "        [-0.0029, -0.1890, -0.0073,  0.1643, -0.1134,  0.0102, -0.1514, -0.1684,\n",
      "         -0.0726, -0.0770,  0.0642, -0.1711,  0.0053,  0.1334,  0.2014,  0.0462,\n",
      "         -0.0664,  0.2028, -0.1558,  0.0735],\n",
      "        [-0.0096, -0.2124, -0.1876, -0.0558,  0.0882,  0.1376,  0.1419, -0.1263,\n",
      "          0.0981, -0.2175,  0.1171, -0.1711,  0.0237, -0.2002,  0.1322, -0.0392,\n",
      "         -0.2222, -0.0738, -0.1196,  0.1332],\n",
      "        [-0.0440, -0.0990,  0.2099,  0.0789, -0.0351, -0.1990,  0.0395, -0.0165,\n",
      "          0.1482,  0.1724, -0.0517,  0.0802, -0.0397,  0.0255, -0.0582,  0.1709,\n",
      "          0.1007,  0.1521, -0.0944,  0.1370],\n",
      "        [-0.0229, -0.1863, -0.0317,  0.0274, -0.1300,  0.0475,  0.1870, -0.1942,\n",
      "          0.0669, -0.1945, -0.2061,  0.1279,  0.1332,  0.1788, -0.0511,  0.0605,\n",
      "          0.0386,  0.0581, -0.2103,  0.1408],\n",
      "        [ 0.1262, -0.1605,  0.1483,  0.1719,  0.0756, -0.0527,  0.1082, -0.1213,\n",
      "          0.1227,  0.0989, -0.0075, -0.0566, -0.1290, -0.0872, -0.0042, -0.2042,\n",
      "          0.2202, -0.1299, -0.1655,  0.1046],\n",
      "        [ 0.0124, -0.2070,  0.0671, -0.1978, -0.1377, -0.1576, -0.0560,  0.1366,\n",
      "          0.0528,  0.0371, -0.0940,  0.0125,  0.0607,  0.0901, -0.1651,  0.1041,\n",
      "          0.0264, -0.0904,  0.0441, -0.1007],\n",
      "        [ 0.0227,  0.1331, -0.2162,  0.0679,  0.1908,  0.0165,  0.1584, -0.1771,\n",
      "          0.0381, -0.0392,  0.0839, -0.1778,  0.0921,  0.0255, -0.1252, -0.0679,\n",
      "          0.1379,  0.0853, -0.0272,  0.0022],\n",
      "        [ 0.1774, -0.2042, -0.1315, -0.2055, -0.1191,  0.0162,  0.0471, -0.1104,\n",
      "          0.0155,  0.1582, -0.1645, -0.0852, -0.1058, -0.1062,  0.1072,  0.1506,\n",
      "          0.1375, -0.0424, -0.1760, -0.1233],\n",
      "        [-0.1508, -0.1238,  0.1980,  0.0059, -0.1908,  0.0656,  0.0962,  0.0395,\n",
      "          0.0033,  0.1061, -0.0133,  0.1678,  0.0736, -0.1712, -0.1221, -0.0463,\n",
      "         -0.1507, -0.0528,  0.0556,  0.0141],\n",
      "        [ 0.1228, -0.0668, -0.0046,  0.0489,  0.2087,  0.2136, -0.0585, -0.0513,\n",
      "          0.0136, -0.1258,  0.1790,  0.1918,  0.2027,  0.1427,  0.0462,  0.1078,\n",
      "         -0.0466,  0.1787, -0.0017, -0.0244],\n",
      "        [ 0.1945, -0.2158, -0.0589, -0.0879,  0.0437, -0.1979, -0.1897, -0.0492,\n",
      "         -0.1982, -0.1161, -0.0773,  0.0869,  0.1095, -0.1110, -0.2185, -0.0012,\n",
      "         -0.0914,  0.0672, -0.0380, -0.0233],\n",
      "        [ 0.2147,  0.2120,  0.1384,  0.2001,  0.1203, -0.1272, -0.2179,  0.1881,\n",
      "          0.0849, -0.0319,  0.1178, -0.1452, -0.0855, -0.1005, -0.0706,  0.0440,\n",
      "         -0.0928,  0.0308,  0.1592, -0.0951],\n",
      "        [-0.1701,  0.2007,  0.1529,  0.1188,  0.2176,  0.1912, -0.1981,  0.0179,\n",
      "         -0.2034,  0.2027,  0.0175, -0.2200,  0.1030, -0.1883,  0.1994, -0.1854,\n",
      "         -0.2211,  0.0156, -0.1067, -0.0092],\n",
      "        [ 0.1899,  0.1034,  0.1777, -0.0642,  0.1461, -0.1080,  0.0610, -0.1411,\n",
      "          0.1872, -0.1810, -0.1590, -0.0117,  0.0203, -0.1761, -0.1901, -0.1283,\n",
      "         -0.2228,  0.2127, -0.2003,  0.0860],\n",
      "        [-0.1174, -0.0800,  0.1455, -0.1721,  0.1359, -0.0669,  0.1911,  0.0112,\n",
      "         -0.1684,  0.2158,  0.0888, -0.0403, -0.0059,  0.0694,  0.0280,  0.0827,\n",
      "         -0.0249,  0.0037, -0.1412,  0.0704],\n",
      "        [-0.0361, -0.1271, -0.1382, -0.1244, -0.0230, -0.2102,  0.1647,  0.1262,\n",
      "          0.0872, -0.0052,  0.1848,  0.1526,  0.0057, -0.1710, -0.0748, -0.0130,\n",
      "         -0.1527,  0.1573, -0.0773,  0.0826],\n",
      "        [ 0.1888,  0.1837,  0.0294, -0.0599, -0.1371,  0.0027, -0.1738,  0.1986,\n",
      "          0.1480,  0.1666, -0.1419, -0.0316, -0.1366,  0.2129,  0.0162,  0.2197,\n",
      "          0.0834, -0.1290, -0.1905,  0.0152],\n",
      "        [-0.2197, -0.0211, -0.1674,  0.0544,  0.1636, -0.1772,  0.2033, -0.1671,\n",
      "         -0.2018,  0.1484,  0.0061, -0.0127,  0.1937, -0.1468, -0.1333, -0.1137,\n",
      "         -0.0825, -0.1139,  0.1885,  0.1857],\n",
      "        [-0.0569, -0.2232, -0.0996,  0.1605, -0.1610, -0.1691,  0.0999, -0.0181,\n",
      "          0.1158,  0.0393,  0.0842, -0.2032,  0.0239, -0.0397,  0.0655,  0.1565,\n",
      "         -0.2043,  0.2161,  0.0223,  0.2101],\n",
      "        [-0.0105, -0.0351, -0.0905,  0.1990,  0.2003, -0.0381, -0.1273,  0.2064,\n",
      "         -0.0948,  0.1570, -0.0687, -0.1025,  0.0072,  0.0848,  0.1500, -0.1275,\n",
      "         -0.0477,  0.1443,  0.0504,  0.0271],\n",
      "        [ 0.1235,  0.1941,  0.0801,  0.2155,  0.2198,  0.1402,  0.0577,  0.1630,\n",
      "          0.2035,  0.1202, -0.1113, -0.2230, -0.0803,  0.0638,  0.0463,  0.1590,\n",
      "          0.1153,  0.1248,  0.0445, -0.1359],\n",
      "        [ 0.2207, -0.1240,  0.0305,  0.1018, -0.0657, -0.1721, -0.1815, -0.0987,\n",
      "          0.1770,  0.0475, -0.1123, -0.0767,  0.0822, -0.0171,  0.0940, -0.2066,\n",
      "          0.1618, -0.0196,  0.1707,  0.0893],\n",
      "        [ 0.1697, -0.0779, -0.0344, -0.1169,  0.1710,  0.2027, -0.1551,  0.2067,\n",
      "          0.0150, -0.1811,  0.0344,  0.1564,  0.0317, -0.1817, -0.0389,  0.1446,\n",
      "          0.0811,  0.1713,  0.1136, -0.1338],\n",
      "        [-0.0308, -0.1338,  0.0974,  0.0247,  0.0597, -0.1886, -0.1710, -0.1102,\n",
      "          0.1194, -0.1814, -0.1215, -0.2022,  0.1394, -0.0054,  0.0977, -0.0988,\n",
      "         -0.0258,  0.0213,  0.1902, -0.0500],\n",
      "        [-0.1683,  0.1347, -0.1966,  0.1837,  0.0718,  0.1276, -0.0802, -0.0155,\n",
      "          0.0113,  0.1264,  0.1747, -0.1558,  0.1614, -0.1592,  0.1848, -0.1541,\n",
      "          0.0237, -0.0537, -0.0084, -0.1662],\n",
      "        [ 0.1527,  0.0152, -0.0800, -0.1766, -0.2058,  0.0649,  0.0149,  0.1946,\n",
      "          0.0844, -0.1678,  0.1220,  0.0763,  0.0478, -0.1530, -0.1546, -0.0180,\n",
      "          0.1434,  0.0297, -0.0180, -0.1465]], requires_grad=True)\n",
      "torch.Size([30, 20])\n"
     ]
    }
   ],
   "source": [
    "params = list(m.parameters())\n",
    "print(len(params))       \n",
    "\n",
    "#print(params[1])\n",
    "print(params[0])\n",
    "print(params[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
